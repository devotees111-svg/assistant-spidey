# assistant-spidey
Voiceâ€‘driven AI assistant with Geminiâ€‘ADK style tools, MCPâ€‘based memory system, and modular agent architecture. Built as a capstone project for the Kaggle Agents Intensive course.

# ğŸ•·ï¸ Assistant Spidey â€“ Voiceâ€‘Driven AI Agent (Geminiâ€‘ADK Inspired, MCP Memory)

Assistant Spidey is a **voiceâ€‘controlled AI agent** built for the  
**Kaggle Agents Intensive Capstone Project**.

It combines:

- ğŸ¤ **Speech Recognition**  
- ğŸ¤– **LLM Agent Brain (Gemini/OpenAI style reasoning)**  
- ğŸ§° **Tool System (like Gemini ADK)**  
- ğŸ’¾ **Memory Engine (MCPâ€‘style longâ€‘term memory)**  
- ğŸ—£ **Textâ€‘toâ€‘Speech responses**  
- ğŸ–¥ **Desktop app control**  
- ğŸŒ **Live data tools (weather, web search, Wikipedia)**  
- ğŸ”Š **Kaggleâ€‘friendly simulation using WAV audio files**

This repo contains the full source code, demo files, and documentation for running and modifying Assistant Spidey.

---

## ğŸš€ Features

### âœ… Voice Commands  
Spidey listens to your voice and executes commands such as:

- â€œWhatâ€™s the weather in Mumbai?â€  
- â€œWho is Iron Man?â€  
- â€œOpen Chrome.â€  
- â€œRemember that my name is Abhishek.â€  
- â€œWhat is my name?â€  
- â€œSearch for Avengers release date.â€

### âœ… Gemini ADKâ€‘Inspired Tool System  
Modular **tools** (Python functions) that the agent can call:

- ğŸŒ¤ Weather Tool  
- ğŸŒ Web Search Tool  
- ğŸ“š Wikipedia Tool  
- ğŸ–¥ App Launcher Tool  
- ğŸ“ Memory Add Tool  
- ğŸ” Memory Retrieve Tool  

### âœ… MCPâ€‘Style Memory  
Spidey can *remember* things longâ€‘term:

- Name  
- Preferences  
- Notes  
- Personal facts  
- Conversation history (last 5 messages)

Memory is stored in **memory.json**.

### âœ… Agent Brain (LLMâ€‘Driven)  
Spidey uses an LLM to:

- interpret commands  
- choose correct tools  
- summarize info  
- manage context  
- do fallback chat  

Works with **Gemini**, **OpenAI**, **LLaMA**, or any LLM API.

### âœ… Kaggle-Compatible Demo  
Since Kaggle has *no microphone access*, the notebook uses:

- sample `.wav` audio commands  
- simulated STT processing  
- agent + tool execution  
- memory demonstrating updates  

### âœ… Desktop Execution  
When run locally, it uses:

- microphone input  
- app launching  
- text-to-speech output  
- real-time interaction

---

## ğŸ“ Project Structure

assistant_spidey/
â”‚
â”œâ”€â”€ main.py # main entry: voice loop / text loop
â”œâ”€â”€ agent.py # LLM agent brain + tool routing
â”œâ”€â”€ tools.py # all tools (weather, wiki, search, etc.)
â”œâ”€â”€ memory.py # MCP-like memory storage and retrieval
â”œâ”€â”€ config.py # (optional) environment keys loader
â”‚
â”œâ”€â”€ memory.json # long-term memory
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ samples/ # sample wav audio files for Kaggle
â”‚ â”œâ”€â”€ weather.wav
â”‚ â”œâ”€â”€ who_is_iron_man.wav
â”‚ â””â”€â”€ remember_name.wav
â”‚
â””â”€â”€ demo/
â”œâ”€â”€ demo.mp4
â””â”€â”€ demo.gif


---

## ğŸ§  Architecture Diagram

ğŸ¤ Voice Input (Mic or WAV)
â†“
ğŸ—£ Speech-to-Text (SpeechRecognition / Vosk)
â†“
ğŸ¤– LLM Agent Brain (Gemini/OpenAI)
â†“
ğŸ§° Tool Router (Gemini ADK style)
â”œâ”€â”€ Weather Tool
â”œâ”€â”€ Search Tool
â”œâ”€â”€ Wikipedia Tool
â”œâ”€â”€ App Launcher
â”œâ”€â”€ Memory Add
â””â”€â”€ Memory Get
â†“
ğŸ“„ Final Response Text
â†“
ğŸ”Š Text-to-Speech (pyttsx3)


---

## ğŸ›  Installation

### 1ï¸âƒ£ Clone the project
```bash
git clone https://github.com/<your-username>/assistant-spidey.git
cd assistant-spidey
2ï¸âƒ£ Create virtual environment
python -m venv venv
source venv/bin/activate       # macOS / Linux
venv\Scripts\activate          # Windows
3ï¸âƒ£ Install dependencies
pip install -r requirements.txt
4ï¸âƒ£ Create .env for API keys
WEATHER_API_KEY=xxxxx
GEMINI_API_KEY=xxxxx
OPENAI_API_KEY=xxxxx
â–¶ï¸ Usage
ğŸ”¹ Run locally (voice)
python main.py
Say commands like:

â€œSpidey, whatâ€™s the weather?â€

â€œOpen Chrome.â€

â€œRemember that my name is Abhishek.â€

ğŸ”¹ Run in Kaggle Notebook (audio simulation)
Replace microphone input with:

text = listen_file("samples/weather.wav")
ğŸ¤– LLM Integration
Replace placeholder inside call_llm():

Gemini
import google.generativeai as genai
genai.configure(api_key=GEMINI_API_KEY)
response = genai.GenerativeModel("gemini-1.5-pro").generate_content(prompt)
OpenAI
from openai import OpenAI
client = OpenAI(api_key=OPENAI_API_KEY)
response = client.chat.completions.create(...)
ğŸ”§ Adding New Tools
Every tool is just a Python function inside tools.py.

Example:

def tool_joke():
    return "Why did the computer freeze? Because it left its Windows open!"
Add to router in agent.py:

if tool == "joke":
    return tool_joke()
ğŸ§ª Sample Commands (for WAV files)
Use these for Kaggle demo:

â€œWhat is the weather in Mumbai?â€

â€œWho is Iron Man?â€

â€œRemember my name is Abhishek.â€

â€œWhat is my name?â€

â€œOpen Chrome.â€

â€œSearch for Spider-Man movie release date.â€

ğŸ¤ Contributing
Fork the repo

Create a branch:

git checkout -b feature/new-tool
Commit:

git commit -m "Added Wikipedia detail tool"
Push:

git push origin feature/new-tool
Open Pull Request

ğŸ’¬ Team Collaboration
Use the GitHub:

Issues tab â†’ track tasks

Projects Board â†’ workflow

Pull Requests â†’ peer review

Wiki â†’ documentation

Branch Protection â†’ secure main branch

ğŸ“„ License
MIT License â€” feel free to modify, reuse, contribute.

ğŸŒ Links
Kaggle Notebook: (add link)

Demo Video: (add link)

GitHub Repo: (add link)
